import { create } from 'zustand';
import { persist } from 'zustand/middleware';
import type { ProcessingEvent, FileContext } from '@shared/engine/types';
import { runAnalysis } from '@shared/engine/pipeline/Orchestrator';
import { analysisService, documentService } from '@shared/api/storage/services';

export type TemplateId = 'academic' | 'minimal' | 'detailed' | 'summary';

export interface MarkingScheme {
  introduction: number;
  body: number;
  conclusion: number;
  presentation: number;
}

interface AnalysisStore {
  questions: string;
  template: TemplateId;
  markingScheme: MarkingScheme;
  totalScore: number;
  isGenerating: boolean;
  processingSteps: ProcessingEvent[];
  selectedDocumentIds: string[];
  result: string | null;
  setQuestions: (q: string) => void;
  setTemplate: (t: TemplateId) => void;
  setMarkingScheme: (scheme: MarkingScheme) => void;
  updateMarkingScheme: (key: keyof MarkingScheme, value: number) => void;
  setSelectedDocumentIds: (ids: string[]) => void;
  startAnalysis: () => Promise<void>;
  resetAnalysis: () => void;
}

const MOCK_RESULT = `
  <div class="space-y-8">
    <div class="text-center border-b-2 border-black pb-4">
        <h1 class="text-4xl font-bold font-serif">Comprehensive Analysis Report</h1>
        <p class="text-zinc-600 mt-2">Generated by Glassmind AI</p>
    </div>

    <section class="space-y-4">
        <h2 class="text-2xl font-bold text-blue-800 border-b border-blue-200 pb-1">1. Introduction</h2>
        <p class="leading-relaxed text-justify">
            This report provides a detailed analysis based on the selected documents. The primary focus is to address the query regarding specific themes and entities identified within the text. The analysis leverages advanced semantic understanding to synthesize information from multiple sources.
        </p>
    </section>

    <section class="space-y-4">
        <h2 class="text-2xl font-bold text-blue-800 border-b border-blue-200 pb-1">2. Key Findings</h2>
        <p class="leading-relaxed text-justify">
            Several critical insights were derived from the document set:
        </p>
        <ul class="list-disc pl-8 space-y-2">
            <li><strong class="text-blue-900">Core Concepts:</strong> The documents consistently refer to foundational principles in the domain.</li>
            <li><strong class="text-blue-900">Methodology:</strong> A rigorous approach to data collection and interpretation is evident.</li>
            <li><strong class="text-blue-900">Implications:</strong> The findings suggest significant impact on future applications and research directions.</li>
        </ul>
    </section>

    <section class="space-y-4">
        <h2 class="text-2xl font-bold text-blue-800 border-b border-blue-200 pb-1">3. Detailed Analysis</h2>
        <p class="leading-relaxed">
           The synthesis of the provided materials highlights a correlation between theoretical models and observed phenomena.
        </p>
        <div class="py-4 flex justify-center">
             <div class="bg-zinc-100 px-6 py-3 rounded border border-zinc-200 font-mono text-sm text-zinc-700">
                Analysis Confidence Score: 98.5%
             </div>
        </div>
         <p class="leading-relaxed text-justify">
            Cross-referencing the data points confirms the validity of the initial hypothesis presented in the query.
        </p>
    </section>

     <section class="space-y-4">
        <h2 class="text-2xl font-bold text-blue-800 border-b border-blue-200 pb-1">4. Conclusion</h2>
        <p class="leading-relaxed text-justify">
           In summary, the documents support a robust conclusion regarding the subject matter. Further investigation into specific edge cases is recommended to refine the model.
        </p>
    </section>
  </div>
`;

export const useAnalysisStore = create<AnalysisStore>()(
  persist(
    (set, get) => ({
      questions: '',
      template: 'academic',
      markingScheme: {
        introduction: 10,
        body: 60,
        conclusion: 20,
        presentation: 10,
      },
      totalScore: 100,
      isGenerating: false,
      processingSteps: [],
      selectedDocumentIds: [],
      result: null,

      setQuestions: (q) => set({ questions: q }),
      setTemplate: (t) => set({ template: t }),
      setMarkingScheme: (scheme) => {
          const total = Object.values(scheme).reduce((a, b) => a + b, 0);
          set({ markingScheme: scheme, totalScore: total });
      },
      updateMarkingScheme: (key, value) => {
        const currentScheme = get().markingScheme;
        const newScheme = { ...currentScheme, [key]: value };
        const total = Object.values(newScheme).reduce((a, b) => a + b, 0);
        set({ markingScheme: newScheme, totalScore: total });
      },
      setSelectedDocumentIds: (ids) => set({ selectedDocumentIds: ids }),

      startAnalysis: async () => {
          const { selectedDocumentIds, questions } = get();
          set({ isGenerating: true, processingSteps: [], result: null });

          try {
             await analysisService.create(questions, selectedDocumentIds);
          } catch (e) {
              console.error("Failed to create analysis record", e);
          }

          let fileContexts: FileContext[] = [];

          try {
              const allDocs = await documentService.getAll();
              fileContexts = selectedDocumentIds.map(id => {
                  const doc = allDocs.find(d => d.id === id);
                  return {
                      id: id,
                      name: doc ? doc.name : 'Document ' + id.substring(0, 4),
                      size: doc ? doc.size : 1000,
                      type: doc ? doc.type : 'application/pdf'
                  };
              });
          } catch (e) {
              console.warn("Could not fetch documents for context, using mock", e);
              fileContexts = selectedDocumentIds.map(id => ({
                  id: id,
                  name: 'Document ' + id.substring(0, 4),
                  size: 1000,
                  type: 'application/pdf'
              }));
          }

          const orchestrator = runAnalysis(fileContexts);

          orchestrator.on('progress', (event: ProcessingEvent) => {
              set((state) => ({
                  processingSteps: [...state.processingSteps, event]
              }));
          });

          orchestrator.on('step-completed', (event: ProcessingEvent) => {
               set((state) => ({
                  processingSteps: [...state.processingSteps, event]
              }));
          });

          orchestrator.on('all-completed', () => {
              setTimeout(() => {
                  set({ isGenerating: false, result: MOCK_RESULT });
              }, 1000);
          });
      },

      resetAnalysis: () => set({ isGenerating: false, processingSteps: [], result: null })
    }),
    {
      name: 'analysis-storage',
      partialize: (state) => ({
          questions: state.questions,
          template: state.template,
          markingScheme: state.markingScheme,
          selectedDocumentIds: state.selectedDocumentIds,
          result: state.result
      }),
    }
  )
);
